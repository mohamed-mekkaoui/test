{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46470ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import os\n",
    "import urllib.request\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89ee65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_root = os.path.join(os.getcwd(), 'graphrag_index')\n",
    "os.makedirs(os.path.join(index_root, 'input'), exist_ok=True)\n",
    "url = \"https://www.gutenberg.org/cache/epub/7785/pg7785.txt\"\n",
    "file_path = os.path.join(index_root, 'input', 'davinci.txt')\n",
    "urllib.request.urlretrieve(url, file_path)\n",
    "with open(file_path, 'r+', encoding='utf-8') as file:\n",
    "    # We use the first 934 lines of the text file, because the later lines are not relevant for this example.\n",
    "    # If you want to save api key cost, you can truncate the text file to a smaller size.\n",
    "    lines = file.readlines()\n",
    "    file.seek(0)\n",
    "    file.writelines(lines[:934])  # Decrease this number if you want to save api key cost.\n",
    "    file.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb8abe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohamed\\Desktop\\Cnp\\Microsoft_Graph\\graphrag\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'store_entity_semantic_embeddings' from 'graphrag.query.input.loaders.dfs' (c:\\Users\\Mohamed\\Desktop\\Cnp\\Microsoft_Graph\\graphrag\\graphrag\\query\\input\\loaders\\dfs.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgraphrag\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquery\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontext_builder\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mentity_extraction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EntityVectorStoreKey\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgraphrag\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquery\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexer_adapters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# read_indexer_covariates,\u001b[39;00m\n\u001b[32m      6\u001b[39m     read_indexer_entities,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     read_indexer_text_units,\n\u001b[32m     10\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgraphrag\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquery\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minput\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloaders\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdfs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     store_entity_semantic_embeddings,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgraphrag\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquery\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgraphrag\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquery\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membedding\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbedding\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'store_entity_semantic_embeddings' from 'graphrag.query.input.loaders.dfs' (c:\\Users\\Mohamed\\Desktop\\Cnp\\Microsoft_Graph\\graphrag\\graphrag\\query\\input\\loaders\\dfs.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tiktoken\n",
    "from graphrag.query.context_builder.entity_extraction import EntityVectorStoreKey\n",
    "from graphrag.query.indexer_adapters import (\n",
    "    # read_indexer_covariates,\n",
    "    read_indexer_entities,\n",
    "    read_indexer_relationships,\n",
    "    read_indexer_reports,\n",
    "    read_indexer_text_units,\n",
    ")\n",
    "from graphrag.query.input.loaders.dfs import (\n",
    "    store_entity_semantic_embeddings,\n",
    ")\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.embedding import OpenAIEmbedding\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.question_gen.local_gen import LocalQuestionGen\n",
    "from graphrag.query.structured_search.local_search.mixed_context import (\n",
    "    LocalSearchMixedContext,\n",
    ")\n",
    "from graphrag.query.structured_search.local_search.search import LocalSearch\n",
    "from graphrag.vector_stores import MilvusVectorStore\n",
    "\n",
    "\n",
    "output_dir = os.path.join(index_root, \"output\")\n",
    "subdirs = [os.path.join(output_dir, d) for d in os.listdir(output_dir)]\n",
    "latest_subdir = max(subdirs, key=os.path.getmtime)  # Get latest output directory\n",
    "INPUT_DIR = os.path.join(latest_subdir, \"artifacts\")\n",
    "\n",
    "\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "RELATIONSHIP_TABLE = \"create_final_relationships\"\n",
    "COVARIATE_TABLE = \"create_final_covariates\"\n",
    "TEXT_UNIT_TABLE = \"create_final_text_units\"\n",
    "COMMUNITY_LEVEL = 2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843662a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "entity_embedding_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")\n",
    "\n",
    "entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)\n",
    "description_embedding_store = MilvusVectorStore(\n",
    "    collection_name=\"entity_description_embeddings\",\n",
    ")\n",
    "# description_embedding_store.connect(uri=\"http://localhost:19530\") # For Milvus docker service\n",
    "description_embedding_store.connect(uri=\"./milvus.db\") # For Milvus Lite\n",
    "entity_description_embeddings = store_entity_semantic_embeddings(\n",
    "    entities=entities, vectorstore=description_embedding_store\n",
    ")\n",
    "print(f\"Entity count: {len(entity_df)}\")\n",
    "entity_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d753f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_df = pd.read_parquet(f\"{INPUT_DIR}/{RELATIONSHIP_TABLE}.parquet\")\n",
    "relationships = read_indexer_relationships(relationship_df)\n",
    "\n",
    "print(f\"Relationship count: {len(relationship_df)}\")\n",
    "relationship_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3c18c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "reports = read_indexer_reports(report_df, entity_df, COMMUNITY_LEVEL)\n",
    "\n",
    "print(f\"Report records: {len(report_df)}\")\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb3a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"OPENAI_API_KEY\"]  # Your OpenAI API key\n",
    "llm_model = \"gpt-4o\"  # Or gpt-4-turbo-preview\n",
    "embedding_model = \"text-embedding-3-small\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    model=llm_model,\n",
    "    api_type=OpenaiApiType.OpenAI,\n",
    "    max_retries=20,\n",
    ")\n",
    "token_encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "text_embedder = OpenAIEmbedding(\n",
    "    api_key=api_key,\n",
    "    api_base=None,\n",
    "    api_type=OpenaiApiType.OpenAI,\n",
    "    model=embedding_model,\n",
    "    deployment_name=embedding_model,\n",
    "    max_retries=20,\n",
    ")\n",
    "\n",
    "context_builder = LocalSearchMixedContext(\n",
    "    community_reports=reports,\n",
    "    text_units=text_units,\n",
    "    entities=entities,\n",
    "    relationships=relationships,\n",
    "    covariates=None, #covariates,#todo\n",
    "    entity_text_embeddings=description_embedding_store,\n",
    "    embedding_vectorstore_key=EntityVectorStoreKey.ID,  # if the vectorstore uses entity title as ids, set this to EntityVectorStoreKey.TITLE\n",
    "    text_embedder=text_embedder,\n",
    "    token_encoder=token_encoder,\n",
    ")\n",
    "\n",
    "\n",
    "local_context_params = {\n",
    "    \"text_unit_prop\": 0.5,\n",
    "    \"community_prop\": 0.1,\n",
    "    \"conversation_history_max_turns\": 5,\n",
    "    \"conversation_history_user_turns_only\": True,\n",
    "    \"top_k_mapped_entities\": 10,\n",
    "    \"top_k_relationships\": 10,\n",
    "    \"include_entity_rank\": True,\n",
    "    \"include_relationship_weight\": True,\n",
    "    \"include_community_rank\": False,\n",
    "    \"return_candidate_context\": False,\n",
    "    \"embedding_vectorstore_key\": EntityVectorStoreKey.ID,  # set this to EntityVectorStoreKey.TITLE if the vectorstore uses entity title as ids\n",
    "    \"max_tokens\": 12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "}\n",
    "\n",
    "llm_params = {\n",
    "    \"max_tokens\": 2_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 1000=1500)\n",
    "    \"temperature\": 0.0,\n",
    "}\n",
    "\n",
    "search_engine = LocalSearch(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    llm_params=llm_params,\n",
    "    context_builder_params=local_context_params,\n",
    "    response_type=\"multiple paragraphs\",\n",
    ")\n",
    "\n",
    "\n",
    "result = await search_engine.asearch(\"Tell me about Leonardo Da Vinci\")\n",
    "print(result.response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b06fd26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64acff16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d1ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
